---
title: "Homework1_Question1"
author: "Hannah Zmuda"
output:
  pdf_document:
    df_print: paged
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r library, include = FALSE}
library(locfit)
library(logspline)
```
# Question 1


The goal of this problem is to find the inverse CDF of the given density:

$$ f_X(x) = exp(x - e^x)$$

This will be done by creating an algorithm to simulate the standard extreme value distribution.
In order to find the distribution of the given density, i first find the CDF of the density by integrating the equation above:
$$F_x(x) = -e^{-e^{x}}$$
And then take the inverse of the equation:
$$F_x^{-1}(x) = ln(-ln(-x))$$

```{r CDF Inverse}
set.seed(200)
n <- 1000 #sample number
U1 <- runif(n,0,1) #Random Number Generator, numbers are evenly distributed between 0 and 1
f <- function(x){exp(x-exp(x))}#the standard extreme value distribution density function
q <- function(U1){log(-log(1-U1))}#inverse of the standard extreme value distribution density function, run uniform data through (U1)
#histogram of simulated data
hist(q(U1), prob = TRUE, main = "Standard Extreme Value Distibution", ylim = c(0, 1), xlab = "Values", ylab ="Density")
x <- seq(min(q(U1)), max(q(U1)), 0.01)
lines(x,f(x), col = "blue") #density curve of f(x)

box()
```

\newpage
# Question 2

The objective of question 2 is to develop an algorithm to simulate the Rayleigh distribution. This will be in the form of a function with two inputs: the sample size as n and the scale parameter as $\sigma$.
The Rayleigh distribution has a density of;
$$f(x) = \frac{x}{\sigma^2}exp(-\frac{x^2}{2\sigma^2})$$
Integrating density:
$$F_x(x) = -exp(-\frac{x^2}{2\sigma^2})$$
Inverse of the CDF (of the given density function) is:
$$F^{-1}(x,\sigma) = \sigma\sqrt{-2ln(1 - x)}$$
 
```{r Rayleigh Distribution}
set.seed(475)
#Inverse CDF approach for the Rayleigh distribution
r <- function(n,s){
  U2 <- runif(n,0,1)
  x <- s*sqrt(-2*log(1-U2))
  return(x)
}
#Check normality
qqnorm(r(1000,1))
qqline(r(1000,1),lwd=2,col=2)
#Histogram of simulated data
hist(r(1000,1), prob = TRUE,xlab = "Values (Uniform Distribution)",ylab = "Frequencies",main = "Histogram of Simulated Rayleigh Distribution")
```

\newpage
# Question 3

When using Bayesian Inference, we sometimes simulate the prior, $\theta$, and maximize it to ensure we are maximizing the mean of the distribution. This can be done by accepting $\theta$ as $u \le \frac{f(x|\theta)}{f(x|\hat{\theta})}$ where $u ~ U(0,1)$ and $\hat{\theta}$ is the MLE from maximizing $f(x|\theta)$. Because we are given the following:

$$u \le \frac{f(x|\theta)}{f(x|\hat{\theta})}$$
Based on this equation, we can simplify the equation through the following proof:
$$u \le \frac{f(x|\theta)}{\int_{\theta}^{}\theta e^{-\theta x}\pi(\theta) d\theta}$$
$$u \le \frac{\theta e^{-\theta x}}{\int_{\theta}^{}\theta e^{-\theta x}(\frac{\beta^\alpha \theta^{\alpha - 1}e^{-\beta \theta}}{\gamma(\alpha)})d\theta}$$
$$u \le \frac{1}{(\frac{\beta^\alpha}{\gamma(\alpha)})} \frac{\theta e^{-\theta x}}{\int_{0}^{1}\theta e^{-\theta x} \theta^{\alpha - 1} e^{-\beta \theta}   d\theta}$$
Because $\pi(\theta)$ does not depend on $x$, we can take that out of the integral.
$$u \le \frac{1}{(\frac{\beta^\alpha \theta^{\alpha - 1}e^{-\beta \theta}}{\gamma(\alpha)})} \frac{\theta e^{-\theta x}}{\frac{(-x^\theta +1)(e^{-\theta x})}{x^2}}$$
$$u \le \frac{1}{M} \frac{f(\theta)}{g(\theta)}$$
With this in mind, we can set our equations as follows:

$$f(\theta) = \theta e^{-\theta x}$$
$$g(\theta) = \theta e^{-\theta x}$$
$$M = \frac{\beta^\alpha x^{\alpha - 1} e^{-\beta x}}{\gamma(\alpha)}$$
These can be applied to find the posterior density $P(\theta|x)$.

```{r Conjugate Prior}
#Functions
f <- function(t,x){return(t*exp(-t*x))}
acceptReject <- function(alpha,beta,n,x){
  #MLE/theta hat equation
  MLE <- 1/x
  #number of times theta hat is accepted
  acceptRate <- 0
  #number of times gone through loop
  i <- 1
  #initalize the output vector
  result <- vector(length = n)
  while(acceptRate <= n){
    #step2a: generate U2 to be a uniform distribution
    U2 <- runif(1)
    #step2b: create theta in terms of a gamma distribution
    theta <- rgamma(1,shape = alpha + 1, rate = beta + x)
    #step 3: accept U2 and set theta=U2, if U2 <= f(theta)/f(MLE)
    if(U2 <= f(theta,x)/f(MLE,x)){
      acceptRate = acceptRate + 1
      result[acceptRate] = theta
    }
    i = i + 1
  }
  return(list(result,acceptRate))
}

#posterior
set.seed(100)
n <- 1000#number of samples
alpha <- 4 #alpha
beta <- 2 #beta
x <- 0.5 #x-value
X <- acceptReject(alpha,beta,n,x)
result <- X[[1]]
#calculating acceptance rate

acceptRate <- X[[2]]/n
print(X)

hist(result, probability = T, breaks = 20,xlim = c(0,5),ylim = c(0,1),main = paste("Acceptance Rate:", acceptRate))

```

\newpage
# Question 4

```{r Gauss Quad}
library(pracma)
##  Quadrature with Gauss-Legendre nodes and weights
#evaluation points: sqrt(3/5),0,-sqrt(3/5)
#function
f <- function(x) x*exp(2*x)
# m = 2n-1 = (2*3)-1 = 5
cc <- gaussLegendre(3,-1,1)
#sum the weights*f(x)
Q <- sum(cc$w * f(cc$x*2 + 2))*2
#print weights
print(cc) #weights and x values

print(Q) #Approximate Value

integrand <-function(x) x*exp(2*x)
exact <- integrate(f,0,4)
exactValue <- exact$value
print(exactValue)#"Exact Value"
error <- abs((Q-exactValue)/exactValue)*100
print(error)#error
```
